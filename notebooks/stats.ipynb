{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u1537782/Projects/tradutor_dataset/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from collections import Counter\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "N_PROC = mp.cpu_count()\n",
    "TOKENIZER = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = datasets.load_dataset(\"u1537782/PTradutor\", \"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3965207/3965207 [00:01<00:00, 2663930.16 examples/s]\n",
      "Filter (num_proc=96): 100%|██████████| 1734/1734 [00:00<00:00, 2188.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'source', 'domain', 'pt', 'en'],\n",
       "        num_rows: 1132\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['idx', 'source', 'domain', 'pt', 'en'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = raw.filter(lambda x: x[\"en\"].lower().startswith(\"list of recent\"), num_proc=N_PROC)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lista das mudanças recentes a todas as páginas para as quais a página fornecida contém links (ou de todas as que pertencem à categoria fornecida). As suas páginas vigiadas aparecem a negrito. Opções das mudanças recentes Legenda: N Esta edição criou uma nova página (lista de páginas novas) m Esta é uma edição menor b Esta edição foi feita por um robô (±123) Alteração no tamanho da página, em bytes Mostrar as últimas 50 | 100 | 250 | 500 mudanças nos últimos 1 | 3 | 7 | 14 | 30 dias Esconder edições menores | Mostrar robôs | Esconder utilizadores anónimos | Esconder utilizadores registados | Mostrar as minhas edições Mostrar as novas mudanças a partir das 09h43min de 3 de dezembro de 2022 Espaço nominal: todos (Principal) Discussão Utilizador Utilizador Discussão METIS METIS Discussão Ficheiro Ficheiro Discussão MediaWiki MediaWiki Discussão Predefinição Predefinição Discussão Ajuda Ajuda Discussão Categoria Categoria Discussão Propriedade Discussão propriedade Type Type talk Form Form talk Conceito Discussão conceito Inverter seleção Espaço nominal associado'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[\"train\"][\"pt\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples train: 3966538\n",
      "Number of examples valid: 403\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples train:\", len(raw[\"train\"]))\n",
    "print(\"Number of examples valid:\", len(raw[\"valid\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=96): 100%|██████████| 3966538/3966538 [00:25<00:00, 156541.22 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 403/403 [00:00<00:00, 752.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "raw = raw.map(lambda x: {\"n_tkns\": len(TOKENIZER.encode(x[\"pt\"]))}, num_proc=N_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tkns_train: 424010237\n",
      "n_tkns_test: 25607\n"
     ]
    }
   ],
   "source": [
    "n_tkns_raw_train = sum(raw[\"train\"][\"n_tkns\"])\n",
    "print(f\"n_tkns_raw_train: {n_tkns_raw_train}\")\n",
    "\n",
    "n_tkns_raw_valid = sum(raw[\"valid\"][\"n_tkns\"])\n",
    "print(f\"n_tkns_raw_valid: {n_tkns_raw_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 106M/106M [00:03<00:00, 31.6MB/s] \n",
      "Downloading data: 100%|██████████| 358M/358M [00:15<00:00, 23.6MB/s] \n",
      "Downloading data: 100%|██████████| 380M/380M [00:17<00:00, 21.7MB/s] \n",
      "Downloading data: 100%|██████████| 406M/406M [00:06<00:00, 63.3MB/s] \n",
      "Downloading data: 100%|██████████| 293M/293M [00:05<00:00, 49.8MB/s] \n",
      "Downloading data: 100%|██████████| 117k/117k [00:00<00:00, 280kB/s]\n",
      "Generating train split: 100%|██████████| 3065063/3065063 [00:16<00:00, 184466.87 examples/s]\n",
      "Generating test split: 100%|██████████| 347/347 [00:00<00:00, 68503.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "clean = datasets.load_dataset(\"u1537782/PTradutor\", \"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples train: 3065063\n",
      "Number of examples valid: 347\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples train:\", len(clean[\"train\"]))\n",
    "print(\"Number of examples valid:\", len(clean[\"valid\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=96): 100%|██████████| 3065063/3065063 [00:14<00:00, 207484.50 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 715.14 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 3065063/3065063 [00:14<00:00, 206967.38 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 735.32 examples/s] \n"
     ]
    }
   ],
   "source": [
    "clean = clean.map(lambda x: {\"n_tkns_pt\": len(TOKENIZER.encode(x[\"pt\"]))}, num_proc=N_PROC)\n",
    "clean = clean.map(lambda x: {\"n_tkns_en\": len(TOKENIZER.encode(x[\"en\"]))}, num_proc=N_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N tokens train pt: 329344387\n",
      "N tokens test pt: 22316\n"
     ]
    }
   ],
   "source": [
    "n_tkns_clean_train = sum(clean[\"train\"][\"n_tkns_pt\"])\n",
    "print(f\"N tokens train pt: {n_tkns_clean_train}\")\n",
    "\n",
    "n_tkns_clean_valid = sum(clean[\"valid\"][\"n_tkns_pt\"])\n",
    "print(f\"N tokens valid pt: {n_tkns_clean_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'default', 'journalistic', 'literature', 'web', 'politics', 'legal', 'social_media'}\n"
     ]
    }
   ],
   "source": [
    "domains = set(clean[\"train\"][\"domain\"])\n",
    "print(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_by_domain(dataset):\n",
    "    print(\"\\t\".join([\"domain\", \"n_examples\", \"n_tkns_pt\", \"min_pt\", \"max_pt\", \"avg_pt\", \"n_tkns_en\", \"min_en\", \"max_en\", \"avg_en\"]))\n",
    "    for domain in domains:\n",
    "        ds = dataset.filter(lambda x: x[\"domain\"] == domain, num_proc=N_PROC)\n",
    "        if not len(ds):\n",
    "            continue\n",
    "        info = [\n",
    "            domain,\n",
    "            len(ds),\n",
    "            # pt\n",
    "            sum(ds[\"n_tkns_pt\"]),\n",
    "            min(ds[\"n_tkns_pt\"]),\n",
    "            max(ds[\"n_tkns_pt\"]),\n",
    "            round(sum(ds[\"n_tkns_pt\"]) / len(ds), 1), # avg\n",
    "            # en\n",
    "            sum(ds[\"n_tkns_en\"]),\n",
    "            min(ds[\"n_tkns_en\"]),\n",
    "            max(ds[\"n_tkns_en\"]),\n",
    "            round(sum(ds[\"n_tkns_en\"]) / len(ds), 1), # avg\n",
    "        ]\n",
    "        print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain\tn_examples\tn_tkns_pt\tmin_pt\tmax_pt\tavg_pt\tn_tkns_en\tmin_en\tmax_en\tavg_en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:00<00:00, 3326014.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default', 1171, 74940, 14, 132, 64.0, 55818, 10, 105, 47.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:00<00:00, 3159051.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['journalistic', 1296965, 256531369, 18, 511, 197.8, 190297919, 13, 436, 146.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:00<00:00, 3220343.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['literature', 17181, 1721240, 26, 510, 100.2, 1283728, 18, 360, 74.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:01<00:00, 3055030.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['web', 12624, 2202027, 12, 544, 174.4, 1635845, 11, 416, 129.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:00<00:00, 3203634.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politics', 757, 128201, 25, 524, 169.4, 89347, 15, 380, 118.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:00<00:00, 3124521.45 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legal', 332851, 27463703, 9, 483, 82.5, 20527801, 6, 417, 61.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 3065063/3065063 [00:00<00:00, 3116404.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social_media', 1403514, 41222907, 3, 132, 29.4, 32150831, 2, 121, 22.9]\n"
     ]
    }
   ],
   "source": [
    "print_stats_by_domain(clean[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain\tn_examples\tn_tkns_pt\tmin_pt\tmax_pt\tavg_pt\tn_tkns_en\tmin_en\tmax_en\tavg_en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 840.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['default', 347, 22316, 13, 135, 64.3, 16555, 10, 97, 47.7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 802.23 examples/s] \n",
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 746.47 examples/s]\n",
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 700.49 examples/s] \n",
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 844.73 examples/s]\n",
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 796.98 examples/s] \n",
      "Filter (num_proc=96): 100%|██████████| 347/347 [00:00<00:00, 725.06 examples/s] \n"
     ]
    }
   ],
   "source": [
    "print_stats_by_domain(clean[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 3065063, 3, 544, 107.5, 329344387, 2, 436, 80.3, 246041289]\n"
     ]
    }
   ],
   "source": [
    "info = [\n",
    "    \"All\",\n",
    "    len(clean[\"train\"]),\n",
    "    \n",
    "    # pt\n",
    "    min(clean[\"train\"][\"n_tkns_pt\"]),\n",
    "    max(clean[\"train\"][\"n_tkns_pt\"]),\n",
    "    round(sum(clean[\"train\"][\"n_tkns_pt\"]) / len(clean[\"train\"]), 1), # avg\n",
    "    sum(clean[\"train\"][\"n_tkns_pt\"]),\n",
    "\n",
    "    # en\n",
    "    min(clean[\"train\"][\"n_tkns_en\"]),\n",
    "    max(clean[\"train\"][\"n_tkns_en\"]),\n",
    "    round(sum(clean[\"train\"][\"n_tkns_en\"]) / len(clean[\"train\"]), 1), # avg\n",
    "    sum(clean[\"train\"][\"n_tkns_en\"]),\n",
    "]\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "superclean = datasets.load_dataset(\"u1537782/PTradutor\", \"superclean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples train: 1719002\n",
      "Number of examples valid: 1734\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples train:\", len(superclean[\"train\"]))\n",
    "print(\"Number of examples valid:\", len(superclean[\"valid\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=96): 100%|██████████| 1719002/1719002 [00:12<00:00, 140919.79 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 1734/1734 [00:00<00:00, 3502.67 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 1719002/1719002 [00:11<00:00, 154489.47 examples/s]\n",
      "Map (num_proc=96): 100%|██████████| 1734/1734 [00:00<00:00, 3580.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "superclean = superclean.map(lambda x: {\"n_tkns_pt\": len(TOKENIZER.encode(x[\"pt\"]))}, num_proc=N_PROC)\n",
    "superclean = superclean.map(lambda x: {\"n_tkns_en\": len(TOKENIZER.encode(x[\"en\"]))}, num_proc=N_PROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N tokens train pt: 293628259\n",
      "N tokens valid pt: 110334\n"
     ]
    }
   ],
   "source": [
    "n_tkns_clean_train = sum(superclean[\"train\"][\"n_tkns_pt\"])\n",
    "print(f\"N tokens train pt: {n_tkns_clean_train}\")\n",
    "\n",
    "n_tkns_clean_valid = sum(superclean[\"valid\"][\"n_tkns_pt\"])\n",
    "print(f\"N tokens valid pt: {n_tkns_clean_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'literature', 'politics', 'social_media', 'legal', 'journalistic', 'web'}\n"
     ]
    }
   ],
   "source": [
    "domains = set(superclean[\"train\"][\"domain\"])\n",
    "print(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "domain\tn_examples\tn_tkns_pt\tmin_pt\tmax_pt\tavg_pt\tn_tkns_en\tmin_en\tmax_en\tavg_en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 1719002/1719002 [00:00<00:00, 2516532.63 examples/s]\n",
      "Downloading data:   0%|          | 0.00/288M [23:38<?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['literature', 12082, 1461651, 51, 510, 121.0, 1085296, 37, 360, 89.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 1719002/1719002 [00:00<00:00, 2578962.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['politics', 477, 116836, 53, 524, 244.9, 81801, 36, 380, 171.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 1719002/1719002 [00:00<00:00, 2472799.94 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social_media', 163585, 11622673, 41, 129, 71.0, 9025327, 26, 121, 55.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 1719002/1719002 [00:00<00:00, 2476566.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['legal', 282870, 24635676, 44, 451, 87.1, 18346240, 25, 385, 64.9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 1719002/1719002 [00:00<00:00, 2460481.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['journalistic', 1250982, 253767361, 45, 511, 202.9, 188072054, 25, 433, 150.3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=96): 100%|██████████| 1719002/1719002 [00:00<00:00, 2289220.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['web', 9006, 2024062, 44, 555, 224.7, 1504751, 28, 416, 167.1]\n"
     ]
    }
   ],
   "source": [
    "print_stats_by_domain(superclean[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSL-TL &\t1734 &\t14 &\t135 &\t63.6 &\t110334 &\t10 &\t108 &\t47.2 &\t81821\n"
     ]
    }
   ],
   "source": [
    "info = [\n",
    "    \"DSL-TL\",\n",
    "    str(len(superclean[\"valid\"])),\n",
    "    \n",
    "    # pt\n",
    "    str(min(superclean[\"valid\"][\"n_tkns_pt\"])),\n",
    "    str(max(superclean[\"valid\"][\"n_tkns_pt\"])),\n",
    "    str(round(sum(superclean[\"valid\"][\"n_tkns_pt\"]) / len(superclean[\"valid\"]), 1)),\n",
    "    str(sum(superclean[\"valid\"][\"n_tkns_pt\"])),\n",
    "\n",
    "    # en\n",
    "    str(min(superclean[\"valid\"][\"n_tkns_en\"])),\n",
    "    str(max(superclean[\"valid\"][\"n_tkns_en\"])),\n",
    "    str(round(sum(superclean[\"valid\"][\"n_tkns_en\"]) / len(superclean[\"valid\"]), 1)),\n",
    "    str(sum(superclean[\"valid\"][\"n_tkns_en\"])),\n",
    "]\n",
    "print(\" &\\t\".join(info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 1719002, 41, 555, 170.8, 293628259, 25, 433, 126.9, 218115469]\n"
     ]
    }
   ],
   "source": [
    "info = [\n",
    "    \"All\",\n",
    "    len(superclean[\"train\"]),\n",
    "    \n",
    "    # pt\n",
    "    min(superclean[\"train\"][\"n_tkns_pt\"]),\n",
    "    max(superclean[\"train\"][\"n_tkns_pt\"]),\n",
    "    round(sum(superclean[\"train\"][\"n_tkns_pt\"]) / len(superclean[\"train\"]), 1), # avg\n",
    "    sum(superclean[\"train\"][\"n_tkns_pt\"]),\n",
    "\n",
    "    # en\n",
    "    min(superclean[\"train\"][\"n_tkns_en\"]),\n",
    "    max(superclean[\"train\"][\"n_tkns_en\"]),\n",
    "    round(sum(superclean[\"train\"][\"n_tkns_en\"]) / len(superclean[\"train\"]), 1), # avg\n",
    "    sum(superclean[\"train\"][\"n_tkns_en\"]),\n",
    "]\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
